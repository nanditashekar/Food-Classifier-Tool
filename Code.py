# -*- coding: utf-8 -*-
"""COLLEGPROJECT_Whole.ipynb
Created on Google Colab by Aravind R Krishnan
Automatically generated by Colaboratory.
Original file is located at
    https://colab.research.google.com/drive/1FqQpoNU0hjZUfS0cxW2jCHl6rjHiT2PH
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 1.x

import tensorflow as tf 
print(tf.__version__)
device_name = tf.test.gpu_device_name()
if device_name != '/device:GPU:0':
  raise SystemError('GPU device not found')
print('Found GPU at: {}'.format(device_name))

from tensorflow.python.client import device_lib
device_lib.list_local_devices()

!pip install -q keras

from google.colab import drive
drive.mount("/content/gdrive")
#drive.mount("/content/gdrive", force_remount=True)

tpath="/content/gdrive/My Drive/Colab Notebooks/Project Dataset/training_set"
vpath="/content/gdrive/My Drive/Colab Notebooks/Project Dataset/test_set"

#Part 1: Building the CNN 
from keras.models import Sequential
from keras.layers import Conv2D
from keras.layers import MaxPooling2D
from keras.layers import Flatten
from keras.layers import Dense#fully connected layer
from keras.layers import Dropout
from keras.optimizers import Adam

classifier = Sequential()
#CONVOLUTION 
classifier.add(Conv2D(64, (3, 3), input_shape=(256,256,3), activation='relu', padding='same'))
classifier.add(MaxPooling2D(pool_size=(2,2)))
classifier.add(Dropout(0.2))

#SECOND CONVOLUTION AND POOLING LAYER
classifier.add(Conv2D(128, (3, 3), activation = 'relu', padding='same'))
classifier.add(MaxPooling2D(pool_size = (2, 2)))
classifier.add(Dropout(0.25))

#Third layer
classifier.add(Conv2D(256, (3, 3), activation = 'relu', padding='same'))
classifier.add(MaxPooling2D(pool_size = (2, 2)))
classifier.add(Dropout(0.25))
#Layer 4
classifier.add(Conv2D(512, (3, 3), activation = 'relu', padding='same'))
classifier.add(MaxPooling2D(pool_size = (2, 2)))
classifier.add(Dropout(0.25))

#Layer5
classifier.add(Conv2D(512, (3, 3), activation = 'relu', padding='same'))
classifier.add(MaxPooling2D(pool_size = (2, 2)))
classifier.add(Dropout(0.3))

"""#Layer 6"""
"""classifier.add(Conv2D(64, (3, 3), activation = 'relu', padding='same'))
classifier.add(MaxPooling2D(pool_size = (2, 2)))
classifier.add(Dropout(0.3))
#Layer 7
classifier.add(Conv2D(64, (3, 3), activation = 'relu', padding='same'))
classifier.add(MaxPooling2D(pool_size = (2, 2)))
classifier.add(Dropout(0.3))
#Layer 8
classifier.add(Conv2D(64, (3, 3), activation = 'relu', padding='same'))
classifier.add(MaxPooling2D(pool_size = (2, 2)))
classifier.add(Dropout(0.3))"""


#FLATTENING
classifier.add(Flatten())

#FULL CONNECTION
classifier.add(Dense(units=128, activation='relu'))#HIDDEN LAYER
#classifier.add(Dropout(0.3))
classifier.add(Dense(units=5, activation='softmax'))#OUTPUT LAYER

#Compiling the CNN 
classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics =['accuracy'])
classifier.summary()

#Image preprocessing step to fit the CNN to all the images
from keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator( rotation_range=30,width_shift_range=0.1,
                                   height_shift_range=0.1,
                                   
        rescale=1./255,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True,
        vertical_flip=True,
        fill_mode='nearest')

test_datagen = ImageDataGenerator(rescale=1./255)


training_set = train_datagen.flow_from_directory(tpath,
                                                 target_size = (256,256),
                                                 batch_size =32,
                                                 class_mode = 'categorical')

test_set = test_datagen.flow_from_directory(vpath,
                                            target_size = (256,256),
                                            batch_size =32,
                                            class_mode = 'categorical')
history = classifier.fit_generator(training_set,
                         steps_per_epoch = 4000//32,
                         epochs = 40,
                         validation_data = test_set,
                         validation_steps = 1000//32)

#Accuracy Plot
import matplotlib.pyplot as plt
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title("Model Performance")
plt.xlabel("epoch")
plt.ylabel('Accuracy')
plt.legend(['acc', 'val_acc'])
plt.show()
#Loss Plot
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper right')
plt.show()

# Commented out IPython magic to ensure Python compatibility.
# Predicting images with the trained model using keras.preprocessing 
from keras.preprocessing import image 
import numpy as np
import matplotlib.pyplot as plt 
# %matplotlib inline 
test_image = image.load_img("/content/gdrive/My Drive/Colab Notebooks/Project Dataset/Prediction_test/Dumpling.jpg",  target_size = (256, 256))
test_image = image.img_to_array(test_image)
test_image = np.expand_dims(test_image, axis=0)
array = classifier.predict(test_image)
classes = training_set.class_indices
print(classes)
result = array[0]
print(result)
answer = np.argmax(result)
print(answer)
if answer == 0:
  print("The image resembles a cupcake!")
elif answer == 1:
  print("The image resembles dumplings!")
elif answer == 2:
  print("The image resembles french fries!")
elif answer == 3:
  print("The image resembles fried rice!")
elif answer == 4:
  print("The image resembles a pizza!")

from keras.models import load_model
classifier.save('MINI_PROJECT_MODEL_FINAL.h5')
# Creates a HDF5 file 'my_model.h5'

# Install the PyDrive wrapper & import libraries.
# This only needs to be done once in a notebook.
!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

# Authenticate and create the PyDrive client.
# This only needs to be done once in a notebook.
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

# Create & upload a file.
uploaded = drive.CreateFile({'title': 'MINI_PROJECT_MODEL_FINAL.h5'})
uploaded.SetContentFile('MINI_PROJECT_MODEL_FINAL.h5')
uploaded.Upload()
print('Uploaded file with ID {}'.format(uploaded.get('id')))


#The below code is a part of the trained model file and can be found there.

"""#Loading the model and testing 
from keras.models import load_model
from keras.preprocessing import image 
import numpy as np
classifier = load_model('/content/gdrive/My Drive/MINI_PROJECT_MODEL_FINAL.h5')
classifier.compile(optimizer ='adam', loss='categorical_crossentropy', metrics=['accuracy'])
classifier.summary()
def pred(path):
  test = image.load_img(path, target_size =(256,256))
  test = image.img_to_array(test)
  test = np.expand_dims(test, axis=0)
  result = classifier.predict(test)
  print(result)
  if result[0][0] == 1:
    print("CUPCAKES!")
  elif result[0][1] == 1:
    print("DUMPLINGS")
  elif result[0][2] == 1:
    print("FRENCH FRIES")
  elif result[0][3] == 1:
    print("FRIED RICE")
  else:
    print("PIZZA!")
pred('/content/gdrive/My Drive/Colab Notebooks/Project Dataset/Prediction_test/Dumpling.jpg')
def demo():
    flag=1
    while flag:
        print("Input File Path of Image: ")
        filepath=input()
        pred(filepath)
        print("Enter 0 to Quit, else 1")
        flag=input()
demo()"""
